{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src2.data_loader import *\n",
    "# from src.strategy import *\n",
    "from src2.index import *\n",
    "from src2.strategy2 import *\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score,  classification_report\n",
    "from fredapi import Fred\n",
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "from keras.models import Sequential # deep learning model\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation, GRU, Flatten\n",
    "from keras import optimizers # 옵티마이저 \n",
    "\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 데이터 불러오기 성공\n"
     ]
    }
   ],
   "source": [
    "data = DataGenerator(data_type='db').data_search(ticker='AAPL')\n",
    "data.sort_index(ascending=True, inplace=True)\n",
    "data3 = data.copy()\n",
    "data3.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"open\",\"high\",\"low\",\"close\",\"adjClose\",\"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.loc[\"2010-09-16\":\"2022-10-11\"]\n",
    "# news = pd.read_csv(\"./BAC.csv\", index_col=0)\n",
    "# news = news[[\"label\"]]\n",
    "# news.index.rename(\"Datetime\", inplace=True)\n",
    "# data[\"label\"] = news[\"label\"]\n",
    "# data.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'adjClose', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(df, **kwargs):\n",
    "    \n",
    "    fred = Fred(api_key='d929757b1ad9cd1d5115620a50badb0a')\n",
    "    \n",
    "    data = df.copy()\n",
    "\n",
    "    data[\"Log_Close\"]                              = np.log(data[\"adjClose\"])\n",
    "    data[\"AC_pct\"]                                 = data['adjClose'].pct_change()\n",
    "    data[\"V_pct\"]                                  = data['volume'].pct_change()\n",
    "    data[\"sma(5)\"]                                 = sma(data, 5)\n",
    "    data[\"sma(20)\"]                                = sma(data, 20)\n",
    "    data[\"High_Yield\"]                             = fred.get_series('BAMLH0A0HYM2', data.index[0]).fillna(method=\"ffill\")\n",
    "    data[\"volume_sma5\"]                            = data[\"volume\"].rolling(5).mean()\n",
    "    data[\"volume_sma20\"]                           = data[\"volume\"].rolling(20).mean()\n",
    "    data[\"T10Y2Y\"]                                 = fred.get_series('T10Y2Y', data.index[0])\n",
    "    data[\"VIX\"]                                    = fred.get_series('VIXCLS', data.index[0])\n",
    "    data[\"RSI\"]                                    = rsi(data, **kwargs)\n",
    "    data[[\"macd\",\"macd_signal\",\"macd_oscillator\"]] = macd(data, **kwargs)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    OBV = []\n",
    "    OBV.append(0)\n",
    "    for i in range(1, len(data['adjClose'])):\n",
    "        if data['adjClose'][i] > data['adjClose'][i-1]: \n",
    "            OBV.append(OBV[-1] + data['volume'][i]) \n",
    "        elif data['adjClose'][i] < data['adjClose'][i-1]:\n",
    "            OBV.append( OBV[-1] - data['volume'][i])\n",
    "        else:\n",
    "         OBV.append(OBV[-1])\n",
    "    data['OBV'] = OBV\n",
    "    data[\"OBV_mv20\"] = data[\"OBV\"].rolling(20).mean()\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # signal = []\n",
    "    # for idx in range(len(data['adjClose'])):\n",
    "    #     if idx == 0 or idx+1 == len(data['adjClose']):\n",
    "    #         signal.append(0)   \n",
    "    #     else:\n",
    "    #         if data['adjClose'].iloc[idx-1]> data['adjClose'].iloc[idx] and data['adjClose'].iloc[idx+1]> data['adjClose'].iloc[idx]:\n",
    "    #             signal.append(1) #----- 상승\n",
    "    #         elif data['adjClose'].iloc[idx-1]< data['adjClose'].iloc[idx] and data['adjClose'].iloc[idx+1]< data['adjClose'].iloc[idx]:\n",
    "    #             signal.append(-1) #----- 하락\n",
    "    #         else:\n",
    "    #             signal.append(0) #----- 횡보추세\n",
    "    # data['trend'] = signal\n",
    "\n",
    "    # data[\"diff\"] = data[\"Log_Close\"].diff()\n",
    "    # data[\"trend\"] = [1 if data.iloc[i][\"diff\"] > 0 else 0 for i in range(len(data))]\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # data['r_signal']    = [-1 if data.iloc[i]['RSI'] > 70 else 1 if data.iloc[i]['RSI'] < 30 else 0 for i in range(len(data))] \n",
    "    # data['m_signal']    = [-1 if data.iloc[i]['macd'] < data.iloc[i]['macd_signal'] else 1 if data.iloc[i]['macd'] > data.iloc[i]['macd_signal'] else 0 for i in range(len(data))] \n",
    "\n",
    "\n",
    "    # sma_signal = []\n",
    "    # for i in range(len(data[\"adjClose\"])):\n",
    "    #     if data.iloc[i][\"sma(5)\"] < data.iloc[i][\"adjClose\"] and data.iloc[i-1][\"sma(5)\"] > data.iloc[i-1][\"adjClose\"]:\n",
    "    #         sma_signal.append(1)\n",
    "    #     elif data.iloc[i][\"sma(5)\"] > data.iloc[i][\"adjClose\"] and data.iloc[i-1][\"sma(5)\"] < data.iloc[i-1][\"adjClose\"]:\n",
    "    #         sma_signal.append(-1)\n",
    "    #     else:\n",
    "    #         sma_signal.append(0)\n",
    "    # data[\"sma_signal\"] = sma_signal\n",
    "    data[\"signal\"] =  [  1 if data[\"adjClose\"].diff(1).iloc[i]>0 and data[\"adjClose\"].diff(-1).iloc[i]>0\n",
    "                                else -1 if data[\"adjClose\"].diff(1).iloc[i]<0 and data[\"adjClose\"].diff(-1).iloc[i]<0\n",
    "                                else 0 for i in range(len(data))]\n",
    "\n",
    "    # #-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    target = []\n",
    "    for i in range(1, len(data)+1):\n",
    "        target.append(data.iloc[i-1:i, -1:].values.sum())\n",
    "    data['tt'] = target\n",
    "\n",
    "    data['position'] = 0\n",
    "    data['position'].mask(data['tt'] >= 1, 'buy', inplace=True)\n",
    "    data['position'].mask(data['tt'] == 0, 'hold', inplace=True)\n",
    "    data['position'].mask(data['tt'] <= -1, 'sell', inplace=True)\n",
    "\n",
    "    data['position'].mask(data['position'] == 'hold', 0, inplace=True)  # 0은 hold\n",
    "    data['position'].mask(data['position'] == 'buy', 1, inplace=True)   # 1은 매수 \n",
    "    data['position'].mask(data['position'] == 'sell', 2, inplace=True)  # 2는 매도\n",
    "    data['position'] = data['position'].astype('int')\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    # data.drop([\"open\",\"high\",\"low\",\"close\",\"adjClose\",\"tt\",\"m_signal\",\"r_signal\",\"trend\",\"macd_oscillator\",\"macd_signal\",\"volume_sma5\",\"sma_signal\",\"OBV\"], axis=1, inplace=True)\n",
    "    # data.drop([\"Open\",\"High\",\"Low\",\"Close\",\"volume_sma5\",\"macd_oscillator\",\"macd_signal\",\"Log_Close\"], axis=1, inplace=True)\n",
    "    data.drop([\"tt\"], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'adjClose', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟값 분리\n",
    "X = data.drop('position', axis=1)\n",
    "y = data[['position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스탠다드 스케일러 사용 단, 타겟값은 적용하지 않음\n",
    "ms = MinMaxScaler()\n",
    "X  = ms.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=data.columns[:-1], index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습비율\n",
    "# train_size = int(len(X) * 0.85)\n",
    "# X_train, X_test = X.iloc[:train_size, :], X.iloc[train_size:, :]\n",
    "# y_train, y_test = y.iloc[:train_size, :], y.iloc[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X.iloc[:-48, :], X.iloc[-48:, :]\n",
    "y_train, y_test = y.iloc[:-48, :], y.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 26)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강사님의 윈도우 코드 복붙(이건 우리 입맛에 나중에 바꿔도 상관없음)\n",
    "def my_window_data(feature,target, window_size=20):\n",
    "    data = pd.concat([feature,target], axis = 1)\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for i in range(len(data) - window_size-1):\n",
    "        X = data.iloc[i:i+window_size]\n",
    "        y = target.iloc[i+window_size]\n",
    "        X_list.append(np.array(X))      #[[] ,[] ,[] ,[]]\n",
    "        y_list.append(np.array(y))       #[]   \n",
    "    return  np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = my_window_data(X_train, y_train)\n",
    "X_test , y_test = my_window_data(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6393, 20, 27), (6393, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27, 20, 27), (27, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 20\n",
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model_2021/LSTM.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=model_path ,\n",
    "                             monitor='val_accuracy',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',  # 모니터 기준 설정 (val loss) \n",
    "                              patience=20,         # 10회 Epoch동안 개선되지 않는다면 종료\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20, 50)            15600     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 50)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,235\n",
      "Trainable params: 45,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model_LSTM = Sequential()                                     # window_size,  features\n",
    "    model_LSTM.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))) \n",
    "    model_LSTM.add(Dropout(0.2))\n",
    "    model_LSTM.add(LSTM(64, return_sequences=False))\n",
    "    model_LSTM.add(Dropout(0.2))\n",
    "    model_LSTM.add(Dense(units=3 , activation='softmax')) \n",
    "                 #--------------- 멀티분류\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.001) # Learning Rate 학습속도\n",
    "\n",
    "    model_LSTM.compile(optimizer=adam, loss='sparse_categorical_crossentropy',    #------출력층을  3개의 0,1,2 관망매도매수 구간 \n",
    "                                                        #------ sparse_categorical_crossentropy , 원한인코딩안해도됨 정수그대로 ,  \n",
    "                                                        # integer type 클래스 -> one-hot encoding하지 않고 정수 형태로 label(y)을 넣어줌\n",
    "    metrics=['accuracy'])                     \n",
    "\n",
    "    print(model_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 1.0240 - accuracy: 0.4660\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55556, saving model to ./model_2021\\LSTM.h5\n",
      "320/320 [==============================] - 7s 9ms/step - loss: 1.0227 - accuracy: 0.4677 - val_loss: 0.9076 - val_accuracy: 0.5556\n",
      "Epoch 2/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.9494 - accuracy: 0.5319\n",
      "Epoch 2: val_accuracy improved from 0.55556 to 0.62963, saving model to ./model_2021\\LSTM.h5\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 0.9496 - accuracy: 0.5315 - val_loss: 0.8785 - val_accuracy: 0.6296\n",
      "Epoch 3/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.9180 - accuracy: 0.5552\n",
      "Epoch 3: val_accuracy did not improve from 0.62963\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.9179 - accuracy: 0.5556 - val_loss: 0.8366 - val_accuracy: 0.6296\n",
      "Epoch 4/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.8917 - accuracy: 0.5680\n",
      "Epoch 4: val_accuracy improved from 0.62963 to 0.66667, saving model to ./model_2021\\LSTM.h5\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8923 - accuracy: 0.5667 - val_loss: 0.8298 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.8783 - accuracy: 0.5769\n",
      "Epoch 5: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8783 - accuracy: 0.5766 - val_loss: 0.8687 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8689 - accuracy: 0.5713\n",
      "Epoch 6: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8695 - accuracy: 0.5709 - val_loss: 0.8187 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8693 - accuracy: 0.5784\n",
      "Epoch 7: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 0.8693 - accuracy: 0.5784 - val_loss: 0.8288 - val_accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.8632 - accuracy: 0.5832\n",
      "Epoch 8: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 0.8630 - accuracy: 0.5830 - val_loss: 0.8146 - val_accuracy: 0.6296\n",
      "Epoch 9/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.8603 - accuracy: 0.5803\n",
      "Epoch 9: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8603 - accuracy: 0.5808 - val_loss: 0.8307 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.8586 - accuracy: 0.5833\n",
      "Epoch 10: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8577 - accuracy: 0.5836 - val_loss: 0.8238 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.8537 - accuracy: 0.5853\n",
      "Epoch 11: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8540 - accuracy: 0.5853 - val_loss: 0.8279 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.5838\n",
      "Epoch 12: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8521 - accuracy: 0.5841 - val_loss: 0.8037 - val_accuracy: 0.6296\n",
      "Epoch 13/100\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.8503 - accuracy: 0.5841\n",
      "Epoch 13: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8508 - accuracy: 0.5835 - val_loss: 0.8227 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.8481 - accuracy: 0.5849\n",
      "Epoch 14: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8469 - accuracy: 0.5856 - val_loss: 0.8362 - val_accuracy: 0.6296\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8468 - accuracy: 0.5816\n",
      "Epoch 15: val_accuracy did not improve from 0.66667\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8468 - accuracy: 0.5816 - val_loss: 0.8004 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.8385 - accuracy: 0.5880\n",
      "Epoch 16: val_accuracy improved from 0.66667 to 0.70370, saving model to ./model_2021\\LSTM.h5\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8395 - accuracy: 0.5883 - val_loss: 0.7985 - val_accuracy: 0.7037\n",
      "Epoch 17/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.8394 - accuracy: 0.5919\n",
      "Epoch 17: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8388 - accuracy: 0.5921 - val_loss: 0.7528 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.8360 - accuracy: 0.5943\n",
      "Epoch 18: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8369 - accuracy: 0.5936 - val_loss: 0.8054 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.8383 - accuracy: 0.5853\n",
      "Epoch 19: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8367 - accuracy: 0.5867 - val_loss: 0.8040 - val_accuracy: 0.6296\n",
      "Epoch 20/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.8309 - accuracy: 0.5884\n",
      "Epoch 20: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 0.8311 - accuracy: 0.5885 - val_loss: 0.7888 - val_accuracy: 0.5926\n",
      "Epoch 21/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.5922\n",
      "Epoch 21: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8319 - accuracy: 0.5914 - val_loss: 0.7767 - val_accuracy: 0.6296\n",
      "Epoch 22/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.8271 - accuracy: 0.5931\n",
      "Epoch 22: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8268 - accuracy: 0.5928 - val_loss: 0.8270 - val_accuracy: 0.6296\n",
      "Epoch 23/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.8249 - accuracy: 0.6009\n",
      "Epoch 23: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8258 - accuracy: 0.6000 - val_loss: 0.7847 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.8219 - accuracy: 0.5987\n",
      "Epoch 24: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8212 - accuracy: 0.5991 - val_loss: 0.7937 - val_accuracy: 0.6296\n",
      "Epoch 25/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.8185 - accuracy: 0.5992\n",
      "Epoch 25: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8198 - accuracy: 0.5986 - val_loss: 0.8452 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.8167 - accuracy: 0.6013\n",
      "Epoch 26: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8175 - accuracy: 0.6010 - val_loss: 0.7748 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.8194 - accuracy: 0.5981\n",
      "Epoch 27: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8190 - accuracy: 0.5996 - val_loss: 0.8489 - val_accuracy: 0.5926\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8150 - accuracy: 0.6074\n",
      "Epoch 28: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8150 - accuracy: 0.6074 - val_loss: 0.8003 - val_accuracy: 0.6296\n",
      "Epoch 29/100\n",
      "315/320 [============================>.] - ETA: 0s - loss: 0.8095 - accuracy: 0.6100\n",
      "Epoch 29: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8089 - accuracy: 0.6105 - val_loss: 0.8262 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.8052 - accuracy: 0.6109\n",
      "Epoch 30: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8052 - accuracy: 0.6107 - val_loss: 0.7846 - val_accuracy: 0.6296\n",
      "Epoch 31/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.8007 - accuracy: 0.6067\n",
      "Epoch 31: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8014 - accuracy: 0.6077 - val_loss: 0.8485 - val_accuracy: 0.6296\n",
      "Epoch 32/100\n",
      "313/320 [============================>.] - ETA: 0s - loss: 0.8031 - accuracy: 0.6091\n",
      "Epoch 32: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.8018 - accuracy: 0.6100 - val_loss: 0.8168 - val_accuracy: 0.6296\n",
      "Epoch 33/100\n",
      "314/320 [============================>.] - ETA: 0s - loss: 0.7917 - accuracy: 0.6153\n",
      "Epoch 33: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.7924 - accuracy: 0.6146 - val_loss: 0.7668 - val_accuracy: 0.6296\n",
      "Epoch 34/100\n",
      "312/320 [============================>.] - ETA: 0s - loss: 0.7910 - accuracy: 0.6109\n",
      "Epoch 34: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.7907 - accuracy: 0.6110 - val_loss: 0.8991 - val_accuracy: 0.5926\n",
      "Epoch 35/100\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.7839 - accuracy: 0.6188\n",
      "Epoch 35: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.7853 - accuracy: 0.6179 - val_loss: 0.8677 - val_accuracy: 0.6296\n",
      "Epoch 36/100\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.7799 - accuracy: 0.6108\n",
      "Epoch 36: val_accuracy did not improve from 0.70370\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.7801 - accuracy: 0.6107 - val_loss: 0.7744 - val_accuracy: 0.6296\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7744 - accuracy: 0.6296\n"
     ]
    }
   ],
   "source": [
    "hist_LSTM = model_LSTM.fit(X_train, y_train\n",
    "                  , batch_size= BATCH\n",
    "                  , epochs= EPOCH # \n",
    "                  , validation_data=(X_test, y_test)\n",
    "                  , callbacks= [checkpoint, early_stopping]\n",
    "                 )\n",
    "\n",
    "history_LSTM = model_LSTM.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"grayscale\")\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(hist_LSTM.history[\"loss\"], label=\"train_loss\", color='b', marker='o')\n",
    "# plt.plot(hist.history[\"val_loss\"], label=\"val_loss\", color='k', marker='o')\n",
    "# plt.plot(hist.history[\"accuracy\"], label=\"train_acc\", color='r', marker='o')\n",
    "# plt.plot(hist.history[\"val_accuracy\"], label=\"val_acc\", color='g', marker='o')\n",
    "# plt.title(\"Training Loss and Accuracy\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 351ms/step\n",
      "[[6.75526336e-02 6.26778677e-02 8.69769514e-01]\n",
      " [4.01469648e-01 3.47334445e-01 2.51195908e-01]\n",
      " [1.37049943e-01 1.03453867e-01 7.59496212e-01]\n",
      " [4.39486325e-01 9.41581726e-02 4.66355473e-01]\n",
      " [3.08929741e-01 6.83691129e-02 6.22701108e-01]\n",
      " [9.07524750e-02 1.17154188e-01 7.92093396e-01]\n",
      " [3.09739619e-01 7.15924352e-02 6.18667960e-01]\n",
      " [2.67280757e-01 1.25340670e-01 6.07378602e-01]\n",
      " [3.81153226e-01 5.23815632e-01 9.50310901e-02]\n",
      " [1.44240767e-01 8.47603083e-01 8.15622881e-03]\n",
      " [3.81201953e-02 9.61406171e-01 4.73716442e-04]\n",
      " [4.20833081e-01 5.55061042e-01 2.41058413e-02]\n",
      " [1.84864730e-01 8.08318734e-01 6.81655807e-03]\n",
      " [1.35828987e-01 8.62964272e-01 1.20669871e-03]\n",
      " [1.03147559e-01 8.95085990e-01 1.76644116e-03]\n",
      " [1.30325153e-01 8.68718147e-01 9.56695527e-04]\n",
      " [3.08014750e-01 6.81661308e-01 1.03239417e-02]\n",
      " [1.75043941e-01 8.21406066e-01 3.54999048e-03]\n",
      " [2.33387589e-01 7.61749208e-01 4.86316299e-03]\n",
      " [1.36329755e-01 8.59121382e-01 4.54884302e-03]\n",
      " [1.61939651e-01 8.35926473e-01 2.13391776e-03]\n",
      " [4.14480031e-01 5.31126976e-01 5.43930270e-02]\n",
      " [6.72896430e-02 4.83198501e-02 8.84390533e-01]\n",
      " [2.59006143e-01 8.58325511e-02 6.55161321e-01]\n",
      " [4.00276989e-01 7.59387314e-02 5.23784280e-01]\n",
      " [1.04856424e-01 7.77507201e-02 8.17392886e-01]\n",
      " [9.16381106e-02 1.73750728e-01 7.34611154e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((27,), (27, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_LSTM.predict(X_test)\n",
    "print(pred)\n",
    "pp_LSTM = np.argmax(pred, axis=-1)\n",
    "pp_LSTM.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:0.4897\n"
     ]
    }
   ],
   "source": [
    "f1_LSTM = f1_score(y_test, pp_LSTM, average='macro')\n",
    "print(f\"F1 score:{f1_LSTM:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hold       0.00      0.00      0.00         7\n",
      "         buy       0.71      0.83      0.77        12\n",
      "        sell       0.58      0.88      0.70         8\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.43      0.57      0.49        27\n",
      "weighted avg       0.49      0.63      0.55        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report( y_test, pp_LSTM, target_names=['hold','buy', 'sell']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4  3]\n",
      " [ 0 10  2]\n",
      " [ 1  0  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "res_LSTM = confusion_matrix(y_test, pp_LSTM)\n",
    "print(res_LSTM)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "5T8sAWqWTUEn"
   },
   "outputs": [],
   "source": [
    "class backtest:\n",
    "    def __init__(self, df ,position, result_show =False):\n",
    "        self.df =df\n",
    "        self.position = position\n",
    "        self.result_show = result_show\n",
    "        self.df = self.evaluate(self.df, cost=.001)\n",
    "        self.performance(self.df)\n",
    "\n",
    "\n",
    "    def __get_period(self, df):\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        end_date = df['Datetime'].iloc[-1]\n",
    "        start_date = df['Datetime'].iloc[0]\n",
    "        days_between = (end_date - start_date).days\n",
    "        return abs(days_between)\n",
    "    def __annualize(self, rate, period):\n",
    "        if period < 360:\n",
    "            rate = ((rate-1) / period * 365) + 1\n",
    "        elif period > 365:\n",
    "            rate = rate ** (365 / period)\n",
    "        else:\n",
    "            rate = rate\n",
    "        return round(rate, 4)\n",
    "\n",
    "\n",
    "    def __get_sharpe_ratio(self, df, rf_rate):\n",
    "        '''\n",
    "        Calculate sharpe ratio\n",
    "        :param df:\n",
    "        :param rf_rate:\n",
    "        :return: Sharpe ratio\n",
    "        '''\n",
    "        period = self.__get_period(df)\n",
    "        rf_rate_daily = rf_rate / 365 + 1\n",
    "        df['exs_rtn_daily'] = df['daily_rtn'] - rf_rate_daily\n",
    "        exs_rtn_annual = (self.__annualize(df['acc_rtn'][-1:], period) - 1) - rf_rate\n",
    "        exs_rtn_vol_annual = df['exs_rtn_daily'].std() * np.sqrt(365)\n",
    "        sharpe_ratio = exs_rtn_annual / exs_rtn_vol_annual if exs_rtn_vol_annual>0 else 0\n",
    "        return round(sharpe_ratio, 4)\n",
    "    def evaluate(self, df, cost= .1):\n",
    "        '''\n",
    "        Calculate daily returns and MDDs of portfolio\n",
    "        :param df: The dataframe containing trading position\n",
    "        :param cost: Transaction cost when sell\n",
    "        :return: Returns, MDD\n",
    "        '''\n",
    "        df['signal_price'] = np.nan\n",
    "        df['signal_price'].mask(df[self.position]== 1, df['Adj Close'], inplace=True)\n",
    "        df['signal_price'].mask(df[self.position]== 2, df['Adj Close'], inplace=True)\n",
    "        record = df[[self.position,'signal_price']].dropna()\n",
    "        record['rtn'] = 1\n",
    "        record['rtn'].mask(record[self.position]== 2, (record['signal_price']*(1-cost))/record['signal_price'].shift(1), inplace=True)\n",
    "        record['acc_rtn'] = record['rtn'].cumprod()\n",
    "\n",
    "        df['signal_price'].mask(df[self.position]== 0, df['Adj Close'], inplace=True)\n",
    "        df['rtn'] = record['rtn']\n",
    "        df['rtn'].fillna(1, inplace=True)\n",
    "\n",
    "        df['daily_rtn'] = 1\n",
    "        df['daily_rtn'].mask(df[self.position] == 0, df['signal_price'] / df['signal_price'].shift(1), inplace=True)\n",
    "        df['daily_rtn'].mask(df[self.position] == 2, (df['signal_price']*(1-cost)) / df['signal_price'].shift(1), inplace=True)\n",
    "        df['daily_rtn'].fillna(1, inplace=True)\n",
    "        df['acc_rtn'] = df['daily_rtn'].cumprod()\n",
    "        df['acc_rtn_dp'] = ((df['acc_rtn']-1)*100).round(2)\n",
    "        df['mdd'] = (df['acc_rtn'] / df['acc_rtn'].cummax()).round(4)\n",
    "        df['bm_mdd'] = (df['Adj Close'] / df['Adj Close'].cummax()).round(4)\n",
    "        df.drop(columns='signal_price', inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def performance(self, df, rf_rate=.01):\n",
    "        '''\n",
    "        Calculate additional information of portfolio\n",
    "        :param df: The dataframe with daily returns\n",
    "        :param rf_rate: Risk free interest rate\n",
    "        :return: Number of trades, Number of wins, Hit ratio, Sharpe ratio, ...\n",
    "        '''\n",
    "\n",
    "        rst = {}\n",
    "        rst['no_trades'] = (df[self.position]==1).sum()\n",
    "        rst['no_win'] = (df['rtn']>1).sum()\n",
    "        rst['acc_rtn'] = df['acc_rtn'][-1:].round(4)\n",
    "        rst['hit_ratio'] = round((df['rtn']>1.0).sum() / rst['no_trades'], 4) if rst['no_trades']>0 else 0\n",
    "        rst['avg_rtn'] = round(df[df['rtn']!=1.0]['rtn'].mean(), 4)\n",
    "        rst['period'] = self.__get_period(df)\n",
    "        rst['annual_rtn'] = self.__annualize(rst['acc_rtn'], rst['period'])\n",
    "        rst['bm_rtn'] = round(df.iloc[-1,5]/df.iloc[0,5], 4)\n",
    "        rst['sharpe_ratio'] = self.__get_sharpe_ratio(df, rf_rate)\n",
    "        rst['mdd'] = df['mdd'].min()\n",
    "        rst['bm_mdd'] = df['bm_mdd'].min()\n",
    "        if self.result_show ==True:\n",
    "            print('CAGR: ',round(rst['annual_rtn'].values[0] - 1,5))                       # 연간 수익\n",
    "            print('Accumulated return:',round(rst['acc_rtn'].values[0] - 1,5))         # \n",
    "            print('Average return: ',round(rst['avg_rtn'] - 1,5))\n",
    "            print('Benchmark return :',round(rst['bm_rtn']-1,5))\n",
    "            print('Number of trades: ',(rst['no_trades']))\n",
    "            print('Number of win:',(rst['no_win']))\n",
    "            print('Hit ratio:',(rst['hit_ratio']))\n",
    "            print('Investment period:',(rst['period']/365),'yrs')\n",
    "            print('Sharpe ratio:',(rst['sharpe_ratio']))\n",
    "\n",
    "            print('MDD:',(rst['mdd']-1)*100)\n",
    "            print('Benchmark MDD:',(rst['bm_mdd']-1)*100)\n",
    "            self.res = {'CAGR':(rst['annual_rtn'].values[0] - 1)*100,'Accumulated return':(rst['acc_rtn'].values[0] - 1)*100,'Average return': (rst['avg_rtn'] - 1)*100,'MDD':(rst['mdd']-1)*100}\n",
    "        else:\n",
    "            self.res = {'CAGR':(rst['annual_rtn'].values[0] - 1)*100,'Accumulated return':(rst['acc_rtn'].values[0] - 1)*100,'Average return': (rst['avg_rtn'] - 1)*100,'MDD':(rst['mdd']-1)*100}\n",
    "            print('백테스팅 성공')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "YaP9jP1RaDmO",
    "outputId": "d1ee6e87-dd2c-4a17-add3-f7addde496aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "e0PP-GzeaDmO"
   },
   "outputs": [],
   "source": [
    "data_LSTM = pd.DataFrame({\"actual\":data.iloc[int(len(data) - len(pp_LSTM)):][\"position\"], \"position\":pp_LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "i1q7xVR_aDmO"
   },
   "outputs": [],
   "source": [
    "data_LSTM[\"Adj Close\"] = data3[\"Adj Close\"][int(len(data)) - len(pp_LSTM):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "D70bUn_7aDmO"
   },
   "outputs": [],
   "source": [
    "data_LSTM.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>actual</th>\n",
       "      <th>position</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>145.189148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>139.857986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>138.749832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138.110886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>142.753204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>138.150833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>142.174164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>143.511932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143.621750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>143.152527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>147.026108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>149.202484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-10-25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152.087708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>149.102661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144.560196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>155.482086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153.086044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.400497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144.789810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138.650009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>138.380005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>138.919998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>139.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-11-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>134.869995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>146.869995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150.039993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime  actual  position   Adj Close\n",
       "0  2022-10-06       2         2  145.189148\n",
       "1  2022-10-07       2         0  139.857986\n",
       "2  2022-10-11       2         2  138.749832\n",
       "3  2022-10-12       0         2  138.110886\n",
       "4  2022-10-13       2         2  142.753204\n",
       "5  2022-10-14       2         2  138.150833\n",
       "6  2022-10-17       1         2  142.174164\n",
       "7  2022-10-18       1         2  143.511932\n",
       "8  2022-10-19       0         1  143.621750\n",
       "9  2022-10-20       1         1  143.152527\n",
       "10 2022-10-21       1         1  147.026108\n",
       "11 2022-10-24       1         1  149.202484\n",
       "12 2022-10-25       0         1  152.087708\n",
       "13 2022-10-26       1         1  149.102661\n",
       "14 2022-10-27       1         1  144.560196\n",
       "15 2022-10-28       1         1  155.482086\n",
       "16 2022-10-31       1         1  153.086044\n",
       "17 2022-11-01       0         1  150.400497\n",
       "18 2022-11-02       1         1  144.789810\n",
       "19 2022-11-03       1         1  138.650009\n",
       "20 2022-11-04       0         1  138.380005\n",
       "21 2022-11-07       2         1  138.919998\n",
       "22 2022-11-08       2         2  139.500000\n",
       "23 2022-11-09       0         2  134.869995\n",
       "24 2022-11-10       0         2  146.869995\n",
       "25 2022-11-14       1         2  148.279999\n",
       "26 2022-11-15       1         2  150.039993"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Price')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_df = data_LSTM\n",
    "# 그림 사이즈 설정\n",
    "plt.figure(figsize=( 15,8))\n",
    "\n",
    "# 종가 기준으로 차트를 그림\n",
    "data_LSTM['Adj Close'].plot(grid=True)\n",
    "\n",
    "# position이 1 인경우 초록색으로 해당 종가에 표시\n",
    "plt.scatter(dummy_df.loc[data_LSTM.position == 1].index, dummy_df['Adj Close'][dummy_df.position == 1],\n",
    "            color='green', \n",
    "            label='Buy', \n",
    "            marker = '^', \n",
    "            alpha=1)\n",
    "\n",
    "# position이 -1 인경우 빨간색으로 해당 종가에 표시\n",
    "plt.scatter(dummy_df.loc[dummy_df.position == 2].index, dummy_df['Adj Close'][dummy_df.position == 2],\n",
    "            color='red', \n",
    "            label='Sell', \n",
    "            marker = '^', \n",
    "            alpha=1)\n",
    "\n",
    "# # trend이 1 인경우 초록색으로 해당 종가에 표시\n",
    "# plt.scatter(dummy_df.loc[df.trend == 1].index, dummy_df['Adj Close'][dummy_df.trend == 1],\n",
    "#             color='pink', \n",
    "#             label='up', \n",
    "#             marker = 'o', \n",
    "#             alpha=0.5)\n",
    "\n",
    "# # position이 -1 인경우 빨간색으로 해당 종가에 표시\n",
    "# plt.scatter(dummy_df.loc[dummy_df.trend == 0].index, dummy_df['Adj Close'][dummy_df.trend == 0],\n",
    "#             color='blue', \n",
    "#             label='down', \n",
    "#             marker = 'o', \n",
    "#             alpha=0.5)\n",
    "\n",
    "\n",
    "plt.ylabel('Price ($)')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "-yKaxCcBbNJ-",
    "outputId": "0293d5fa-018e-423c-afb5-86499ec61c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGR:  0.5101\n",
      "Accumulated return: 0.0559\n",
      "Average return:  0.0056\n",
      "Benchmark return : 0.0109\n",
      "Number of trades:  14\n",
      "Number of win: 7\n",
      "Hit ratio: 0.5\n",
      "Investment period: 0.1095890410958904 yrs\n",
      "Sharpe ratio: 26    1.151\n",
      "Name: acc_rtn, dtype: float64\n",
      "MDD: -5.230000000000001\n",
      "Benchmark MDD: -13.260000000000005\n"
     ]
    }
   ],
   "source": [
    "back_LSTM = backtest(data_LSTM,'position',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dddddddddddd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject\\venv\\Final\\Basic_LSTM_return114일 copy.ipynb 셀 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC%20copy.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dddddddddddd\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dddddddddddd' is not defined"
     ]
    }
   ],
   "source": [
    "dddddddddddd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model_2021/GRU.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=model_path ,\n",
    "                             monitor='val_accuracy',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',  # 모니터 기준 설정 (val loss) \n",
    "                              patience=20,         # 10회 Epoch동안 개선되지 않는다면 종료\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 64)                17664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,419\n",
      "Trainable params: 36,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model_GRU = Sequential()\n",
    "    model_GRU.add(GRU(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model_GRU.add(Dense(128))\n",
    "    model_GRU.add(Dropout(0.2))\n",
    "    model_GRU.add(Dense(64))\n",
    "    model_GRU.add(Dropout(0.2))\n",
    "    model_GRU.add(Dense(32))\n",
    "    model_GRU.add(Dropout(0.2))\n",
    "    model_GRU.add(Dense(units = 3 ,  activation='softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "\n",
    "    model_GRU.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "316/321 [============================>.] - ETA: 0s - loss: 0.8912 - accuracy: 0.5644\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61538, saving model to ./model_2021\\GRU.h5\n",
      "321/321 [==============================] - 3s 5ms/step - loss: 0.8935 - accuracy: 0.5633 - val_loss: 0.7934 - val_accuracy: 0.6154\n",
      "Epoch 2/100\n",
      "315/321 [============================>.] - ETA: 0s - loss: 0.8438 - accuracy: 0.5959\n",
      "Epoch 2: val_accuracy did not improve from 0.61538\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8455 - accuracy: 0.5950 - val_loss: 0.8535 - val_accuracy: 0.6154\n",
      "Epoch 3/100\n",
      "315/321 [============================>.] - ETA: 0s - loss: 0.8421 - accuracy: 0.5948\n",
      "Epoch 3: val_accuracy did not improve from 0.61538\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8424 - accuracy: 0.5951 - val_loss: 0.9230 - val_accuracy: 0.6154\n",
      "Epoch 4/100\n",
      "316/321 [============================>.] - ETA: 0s - loss: 0.8373 - accuracy: 0.5975\n",
      "Epoch 4: val_accuracy did not improve from 0.61538\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8382 - accuracy: 0.5973 - val_loss: 0.7456 - val_accuracy: 0.6154\n",
      "Epoch 5/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.8367 - accuracy: 0.5983\n",
      "Epoch 5: val_accuracy did not improve from 0.61538\n",
      "321/321 [==============================] - 1s 5ms/step - loss: 0.8356 - accuracy: 0.5981 - val_loss: 0.9139 - val_accuracy: 0.6154\n",
      "Epoch 6/100\n",
      "316/321 [============================>.] - ETA: 0s - loss: 0.8340 - accuracy: 0.6028\n",
      "Epoch 6: val_accuracy did not improve from 0.61538\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.8318 - accuracy: 0.6039 - val_loss: 0.9393 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "310/321 [===========================>..] - ETA: 0s - loss: 0.8329 - accuracy: 0.6024\n",
      "Epoch 7: val_accuracy improved from 0.61538 to 0.69231, saving model to ./model_2021\\GRU.h5\n",
      "321/321 [==============================] - 2s 5ms/step - loss: 0.8325 - accuracy: 0.6023 - val_loss: 1.0737 - val_accuracy: 0.6923\n",
      "Epoch 8/100\n",
      "317/321 [============================>.] - ETA: 0s - loss: 0.8348 - accuracy: 0.5978\n",
      "Epoch 8: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8350 - accuracy: 0.5978 - val_loss: 0.8399 - val_accuracy: 0.6154\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.8239 - accuracy: 0.6053\n",
      "Epoch 9: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8239 - accuracy: 0.6053 - val_loss: 0.8325 - val_accuracy: 0.6154\n",
      "Epoch 10/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.8299 - accuracy: 0.6046\n",
      "Epoch 10: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8297 - accuracy: 0.6050 - val_loss: 0.8385 - val_accuracy: 0.6154\n",
      "Epoch 11/100\n",
      "315/321 [============================>.] - ETA: 0s - loss: 0.8266 - accuracy: 0.6060\n",
      "Epoch 11: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8262 - accuracy: 0.6062 - val_loss: 0.8050 - val_accuracy: 0.6154\n",
      "Epoch 12/100\n",
      "314/321 [============================>.] - ETA: 0s - loss: 0.8193 - accuracy: 0.6003\n",
      "Epoch 12: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 2s 5ms/step - loss: 0.8209 - accuracy: 0.5995 - val_loss: 0.7769 - val_accuracy: 0.6154\n",
      "Epoch 13/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.8179 - accuracy: 0.6066\n",
      "Epoch 13: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8184 - accuracy: 0.6064 - val_loss: 0.8160 - val_accuracy: 0.6154\n",
      "Epoch 14/100\n",
      "312/321 [============================>.] - ETA: 0s - loss: 0.8122 - accuracy: 0.6043\n",
      "Epoch 14: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8128 - accuracy: 0.6047 - val_loss: 0.7527 - val_accuracy: 0.6923\n",
      "Epoch 15/100\n",
      "317/321 [============================>.] - ETA: 0s - loss: 0.8158 - accuracy: 0.6035\n",
      "Epoch 15: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8158 - accuracy: 0.6036 - val_loss: 0.7558 - val_accuracy: 0.6154\n",
      "Epoch 16/100\n",
      "317/321 [============================>.] - ETA: 0s - loss: 0.8107 - accuracy: 0.6049\n",
      "Epoch 16: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 5ms/step - loss: 0.8103 - accuracy: 0.6048 - val_loss: 0.8645 - val_accuracy: 0.6923\n",
      "Epoch 17/100\n",
      "319/321 [============================>.] - ETA: 0s - loss: 0.8088 - accuracy: 0.6066\n",
      "Epoch 17: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8081 - accuracy: 0.6070 - val_loss: 0.7886 - val_accuracy: 0.6154\n",
      "Epoch 18/100\n",
      "314/321 [============================>.] - ETA: 0s - loss: 0.8016 - accuracy: 0.6115\n",
      "Epoch 18: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8026 - accuracy: 0.6107 - val_loss: 0.8714 - val_accuracy: 0.6923\n",
      "Epoch 19/100\n",
      "312/321 [============================>.] - ETA: 0s - loss: 0.8017 - accuracy: 0.6120\n",
      "Epoch 19: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8018 - accuracy: 0.6112 - val_loss: 0.8563 - val_accuracy: 0.6154\n",
      "Epoch 20/100\n",
      "128/321 [==========>...................] - ETA: 0s - loss: 0.7984 - accuracy: 0.6059"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject\\venv\\Final\\Basic_LSTM_return114일.ipynb 셀 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hist_GRU \u001b[39m=\u001b[39m model_GRU\u001b[39m.\u001b[39;49mfit(X_train, y_train\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                   , batch_size\u001b[39m=\u001b[39;49m BATCH\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                   , epochs\u001b[39m=\u001b[39;49m EPOCH \u001b[39m# \u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                   , validation_data\u001b[39m=\u001b[39;49m(X_test, y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                   , callbacks\u001b[39m=\u001b[39;49m [checkpoint,early_stopping]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                  )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/pythonProject/venv/Final/Basic_LSTM_return114%EC%9D%BC.ipynb#Y131sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m history_GRU \u001b[39m=\u001b[39m model_GRU\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1413\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1411\u001b[0m   context\u001b[39m.\u001b[39masync_wait()\n\u001b[0;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m-> 1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39;49mstep_increment\n\u001b[0;32m   1414\u001b[0m callbacks\u001b[39m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\data_adapter.py:1268\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m steps_remaining\n\u001b[0;32m   1266\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution\u001b[39m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1268\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   1269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_increment\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1270\u001b[0m   \u001b[39m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist_GRU = model_GRU.fit(X_train, y_train\n",
    "                  , batch_size= BATCH\n",
    "                  , epochs= EPOCH # \n",
    "                  , validation_data=(X_test, y_test)\n",
    "                  , callbacks= [checkpoint,early_stopping]\n",
    "                 )\n",
    "\n",
    "history_GRU = model_GRU.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"grayscale\")\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(hist.history[\"loss\"], label=\"train_loss\", color='b', marker='o')\n",
    "# plt.plot(hist.history[\"val_loss\"], label=\"val_loss\", color='k', marker='o')\n",
    "# plt.plot(hist.history[\"accuracy\"], label=\"train_acc\", color='r', marker='o')\n",
    "# plt.plot(hist.history[\"val_accuracy\"], label=\"val_acc\", color='g', marker='o')\n",
    "# plt.title(\"Training Loss and Accuracy\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n",
      "[[0.1519912  0.8293946  0.01861423]\n",
      " [0.21174638 0.7691127  0.0191409 ]\n",
      " [0.3324717  0.60887194 0.05865636]\n",
      " [0.22334376 0.75324786 0.02340846]\n",
      " [0.28964615 0.66293794 0.04741592]\n",
      " [0.18838783 0.78851616 0.02309601]\n",
      " [0.30157954 0.66153425 0.03688621]\n",
      " [0.4350061  0.43988907 0.12510483]\n",
      " [0.10630266 0.00971708 0.8839802 ]\n",
      " [0.30548    0.0313188  0.6632012 ]\n",
      " [0.40621892 0.10327985 0.49050128]\n",
      " [0.1659947  0.03286507 0.80114025]\n",
      " [0.17017873 0.04461795 0.7852033 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13,), (13, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_GRU = model_GRU.predict(X_test)\n",
    "print(pred_GRU)\n",
    "pp_GRU = np.argmax(pred_GRU, axis=-1)\n",
    "pp_GRU.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7916654348373413, 0.6153846383094788]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:0.4571\n"
     ]
    }
   ],
   "source": [
    "f1_GRU = f1_score(y_test, pp_GRU, average='macro')\n",
    "print(f\"F1 score:{f1_GRU:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     holding       0.00      0.00      0.00         4\n",
      "         buy       0.75      0.86      0.80         7\n",
      "        sell       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.38      0.62      0.46        13\n",
      "weighted avg       0.47      0.62      0.52        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report( y_test, pp_GRU, target_names=['holding','buy', 'sell']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 2]\n",
      " [0 6 1]\n",
      " [0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "res_GRU = confusion_matrix(y_test, pp_GRU)\n",
    "print(res_GRU)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "YaP9jP1RaDmO",
    "outputId": "d1ee6e87-dd2c-4a17-add3-f7addde496aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "e0PP-GzeaDmO"
   },
   "outputs": [],
   "source": [
    "data_GRU = pd.DataFrame({\"actual\":data.iloc[int(len(data) - len(pp_GRU)):][\"position\"], \"position\":pp_GRU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "i1q7xVR_aDmO"
   },
   "outputs": [],
   "source": [
    "data_GRU[\"Adj Close\"] = data3[\"Adj Close\"][int(len(data)) - len(pp_GRU):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "D70bUn_7aDmO"
   },
   "outputs": [],
   "source": [
    "data_GRU.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "-yKaxCcBbNJ-",
    "outputId": "0293d5fa-018e-423c-afb5-86499ec61c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGR:  1.435\n",
      "Accumulated return: 0.0747\n",
      "Average return:  0.0153\n",
      "Benchmark return : 0.0109\n",
      "Number of trades:  8\n",
      "Number of win: 4\n",
      "Hit ratio: 0.5\n",
      "Investment period: 0.052054794520547946 yrs\n",
      "Sharpe ratio: 12    2.7775\n",
      "Name: acc_rtn, dtype: float64\n",
      "MDD: -3.420000000000001\n",
      "Benchmark MDD: -13.260000000000005\n"
     ]
    }
   ],
   "source": [
    "back_GRU = backtest(data_GRU,'position',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model_2021/DNN.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=model_path ,\n",
    "                             monitor='val_accuracy',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',  # 모니터 기준 설정 (val loss) \n",
    "                              patience=20,         # 10회 Epoch동안 개선되지 않는다면 종료\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 20, 128)           3712      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20, 256)           33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20, 256)           0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20, 32)            8224      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 20, 32)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 1923      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,883\n",
      "Trainable params: 46,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model_DNN = Sequential()\n",
    "    model_DNN.add(Dense(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model_DNN.add(Dense(256))\n",
    "    model_DNN.add(Dropout(0.2))\n",
    "    model_DNN.add(Dense(32))\n",
    "    model_DNN.add(Dropout(0.2))\n",
    "    model_DNN.add(Flatten())\n",
    "    model_DNN.add(Dense(units = 3 ,  activation='softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "\n",
    "    model_DNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.9693 - accuracy: 0.5061\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61538, saving model to ./model_2021\\DNN.h5\n",
      "321/321 [==============================] - 2s 4ms/step - loss: 0.9694 - accuracy: 0.5060 - val_loss: 0.9855 - val_accuracy: 0.6154\n",
      "Epoch 2/100\n",
      "313/321 [============================>.] - ETA: 0s - loss: 0.9066 - accuracy: 0.5503\n",
      "Epoch 2: val_accuracy improved from 0.61538 to 0.69231, saving model to ./model_2021\\DNN.h5\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.9059 - accuracy: 0.5513 - val_loss: 0.9652 - val_accuracy: 0.6923\n",
      "Epoch 3/100\n",
      "316/321 [============================>.] - ETA: 0s - loss: 0.8952 - accuracy: 0.5585\n",
      "Epoch 3: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8938 - accuracy: 0.5592 - val_loss: 1.2241 - val_accuracy: 0.6154\n",
      "Epoch 4/100\n",
      "312/321 [============================>.] - ETA: 0s - loss: 0.8948 - accuracy: 0.5635\n",
      "Epoch 4: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8931 - accuracy: 0.5641 - val_loss: 0.9827 - val_accuracy: 0.5385\n",
      "Epoch 5/100\n",
      "309/321 [===========================>..] - ETA: 0s - loss: 0.8863 - accuracy: 0.5636\n",
      "Epoch 5: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8874 - accuracy: 0.5616 - val_loss: 0.9772 - val_accuracy: 0.6923\n",
      "Epoch 6/100\n",
      "314/321 [============================>.] - ETA: 0s - loss: 0.8829 - accuracy: 0.5693\n",
      "Epoch 6: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8825 - accuracy: 0.5691 - val_loss: 1.0270 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "311/321 [============================>.] - ETA: 0s - loss: 0.8730 - accuracy: 0.5707\n",
      "Epoch 7: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8759 - accuracy: 0.5691 - val_loss: 0.9334 - val_accuracy: 0.6923\n",
      "Epoch 8/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.8755 - accuracy: 0.5712\n",
      "Epoch 8: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8750 - accuracy: 0.5719 - val_loss: 0.8780 - val_accuracy: 0.5385\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.8750 - accuracy: 0.5661\n",
      "Epoch 9: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 0.8750 - accuracy: 0.5661 - val_loss: 0.9925 - val_accuracy: 0.6923\n",
      "Epoch 10/100\n",
      "309/321 [===========================>..] - ETA: 0s - loss: 0.8722 - accuracy: 0.5712\n",
      "Epoch 10: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8724 - accuracy: 0.5727 - val_loss: 0.9871 - val_accuracy: 0.6923\n",
      "Epoch 11/100\n",
      "307/321 [===========================>..] - ETA: 0s - loss: 0.8761 - accuracy: 0.5695\n",
      "Epoch 11: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 0.8744 - accuracy: 0.5714 - val_loss: 0.9763 - val_accuracy: 0.6923\n",
      "Epoch 12/100\n",
      "317/321 [============================>.] - ETA: 0s - loss: 0.8768 - accuracy: 0.5674\n",
      "Epoch 12: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8753 - accuracy: 0.5681 - val_loss: 0.9694 - val_accuracy: 0.6923\n",
      "Epoch 13/100\n",
      "317/321 [============================>.] - ETA: 0s - loss: 0.8740 - accuracy: 0.5733\n",
      "Epoch 13: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8737 - accuracy: 0.5736 - val_loss: 1.0216 - val_accuracy: 0.6923\n",
      "Epoch 14/100\n",
      "314/321 [============================>.] - ETA: 0s - loss: 0.8689 - accuracy: 0.5693\n",
      "Epoch 14: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8703 - accuracy: 0.5702 - val_loss: 0.8788 - val_accuracy: 0.6923\n",
      "Epoch 15/100\n",
      "319/321 [============================>.] - ETA: 0s - loss: 0.8709 - accuracy: 0.5801\n",
      "Epoch 15: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8707 - accuracy: 0.5806 - val_loss: 0.9454 - val_accuracy: 0.6923\n",
      "Epoch 16/100\n",
      "313/321 [============================>.] - ETA: 0s - loss: 0.8709 - accuracy: 0.5740\n",
      "Epoch 16: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8698 - accuracy: 0.5737 - val_loss: 1.0336 - val_accuracy: 0.6923\n",
      "Epoch 17/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.8752 - accuracy: 0.5745\n",
      "Epoch 17: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8742 - accuracy: 0.5750 - val_loss: 0.9149 - val_accuracy: 0.6154\n",
      "Epoch 18/100\n",
      "316/321 [============================>.] - ETA: 0s - loss: 0.8700 - accuracy: 0.5748\n",
      "Epoch 18: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8695 - accuracy: 0.5744 - val_loss: 1.0816 - val_accuracy: 0.6154\n",
      "Epoch 19/100\n",
      "320/321 [============================>.] - ETA: 0s - loss: 0.8722 - accuracy: 0.5661\n",
      "Epoch 19: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8719 - accuracy: 0.5664 - val_loss: 0.9891 - val_accuracy: 0.6923\n",
      "Epoch 20/100\n",
      "317/321 [============================>.] - ETA: 0s - loss: 0.8669 - accuracy: 0.5767\n",
      "Epoch 20: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8663 - accuracy: 0.5767 - val_loss: 0.9826 - val_accuracy: 0.6154\n",
      "Epoch 21/100\n",
      "318/321 [============================>.] - ETA: 0s - loss: 0.8703 - accuracy: 0.5739\n",
      "Epoch 21: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8698 - accuracy: 0.5744 - val_loss: 1.1155 - val_accuracy: 0.6154\n",
      "Epoch 22/100\n",
      "319/321 [============================>.] - ETA: 0s - loss: 0.8663 - accuracy: 0.5787\n",
      "Epoch 22: val_accuracy did not improve from 0.69231\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 0.8669 - accuracy: 0.5781 - val_loss: 1.0135 - val_accuracy: 0.6923\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0135 - accuracy: 0.6923\n"
     ]
    }
   ],
   "source": [
    "hist_DNN = model_DNN.fit(X_train, y_train\n",
    "                  , batch_size= BATCH\n",
    "                  , epochs= EPOCH\n",
    "                  , validation_data=(X_test, y_test)\n",
    "                  , callbacks= [checkpoint, early_stopping]\n",
    "                 )\n",
    "\n",
    "history_DNN = model_DNN.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "[[0.06633105 0.9282692  0.00539981]\n",
      " [0.09543183 0.89857394 0.00599426]\n",
      " [0.14975311 0.83862865 0.01161815]\n",
      " [0.15414308 0.8307317  0.01512529]\n",
      " [0.13498665 0.8502823  0.01473112]\n",
      " [0.0745088  0.91991436 0.00557689]\n",
      " [0.14219637 0.8416254  0.01617823]\n",
      " [0.28729552 0.68032014 0.0323843 ]\n",
      " [0.38180825 0.05552986 0.5626619 ]\n",
      " [0.38489103 0.08288004 0.53222895]\n",
      " [0.4256822  0.18527961 0.38903823]\n",
      " [0.155868   0.01468485 0.82944715]\n",
      " [0.1302383  0.00546889 0.8642928 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13,), (13, 1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_DNN = model_DNN.predict(X_test)\n",
    "print(pred_DNN)\n",
    "pp_DNN = np.argmax(pred_DNN, axis=-1)\n",
    "pp_DNN.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.013521432876587, 0.692307710647583]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:0.6222\n"
     ]
    }
   ],
   "source": [
    "f1_DNN = f1_score(y_test, pp_DNN, average='macro')\n",
    "print(f\"F1 score:{f1_DNN:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     holding       1.00      0.25      0.40         4\n",
      "         buy       0.75      0.86      0.80         7\n",
      "        sell       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.75      0.70      0.62        13\n",
      "weighted avg       0.79      0.69      0.66        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report( y_test, pp_DNN, target_names=['holding','buy', 'sell']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1]\n",
      " [0 6 1]\n",
      " [0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "res_DNN = confusion_matrix(y_test, pp_DNN)\n",
    "print(res_DNN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "YaP9jP1RaDmO",
    "outputId": "d1ee6e87-dd2c-4a17-add3-f7addde496aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1668420608891,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "e0PP-GzeaDmO"
   },
   "outputs": [],
   "source": [
    "data_DNN = pd.DataFrame({\"actual\":data.iloc[int(len(data) - len(pp_DNN)):][\"position\"], \"position\":pp_DNN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "i1q7xVR_aDmO"
   },
   "outputs": [],
   "source": [
    "data_DNN[\"Adj Close\"] = data3[\"Adj Close\"][int(len(data)) - len(pp_DNN):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "D70bUn_7aDmO"
   },
   "outputs": [],
   "source": [
    "data_DNN.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668420608892,
     "user": {
      "displayName": "신진명",
      "userId": "13294197785714083129"
     },
     "user_tz": -540
    },
    "id": "-yKaxCcBbNJ-",
    "outputId": "0293d5fa-018e-423c-afb5-86499ec61c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGR:  1.4542\n",
      "Accumulated return: 0.0757\n",
      "Average return:  0.0196\n",
      "Benchmark return : 0.0109\n",
      "Number of trades:  8\n",
      "Number of win: 3\n",
      "Hit ratio: 0.375\n",
      "Investment period: 0.052054794520547946 yrs\n",
      "Sharpe ratio: 12    2.7891\n",
      "Name: acc_rtn, dtype: float64\n",
      "MDD: -3.420000000000001\n",
      "Benchmark MDD: -13.260000000000005\n"
     ]
    }
   ],
   "source": [
    "data_DNN = backtest(data_DNN,'position',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN:(0.8779996037483215, 0.692307710647583)\n",
      "LSTM:(0.6956453323364258, 0.692307710647583)\n",
      "GRU:(0.720035970211029, 0.692307710647583)\n"
     ]
    }
   ],
   "source": [
    "print(f'DNN:{np.min(hist_DNN.history[\"val_loss\"]), np.max(hist_DNN.history[\"val_accuracy\"])}')\n",
    "print(f'LSTM:{np.min(hist_LSTM.history[\"val_loss\"]), np.max(hist_LSTM.history[\"val_accuracy\"])}')\n",
    "print(f'GRU:{np.min(hist_GRU.history[\"val_loss\"]), np.max(hist_GRU.history[\"val_accuracy\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538461744785309\n",
      "0.6338461756706237\n",
      "0.6346154063940048\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(hist_DNN.history[\"val_accuracy\"]))\n",
    "print(np.mean(hist_LSTM.history[\"val_accuracy\"]))\n",
    "print(np.mean(hist_GRU.history[\"val_accuracy\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
